{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa97fc1",
   "metadata": {},
   "source": [
    "# Régression : Prédiction de force de morsure de lézards à partir de données anatomiques\n",
    "\n",
    "#### **Auteurs** : Matéo PETITET, Mélodie FLEURY\n",
    "#### **Matière** : UE Prog supervisée par Vincent GUIGUE - 3A IODAA AgroParisTech\n",
    "#### **Date de rendue** : 18 novembre 2024\n",
    "\n",
    "## Présentation des données\n",
    "\n",
    "Les données utilisées sont issues de **Wittorsky & al., \"Proximate determinants of bite force in Anolis lizards\"** <span style=\"color: #BDBDBD\">doi: 10.1111/joa.12394</span>. Il s'agit d'analyser des données morphologiques de lézards du genre *Anolis*, d'espèces et de sexe variables, afin de prédire la force de la morsure en Newtons. Ces données comportent des éléments morphologiques, musculaires, relatives à la masse, la longueur ou la surface. Il y a très peu d'exemples, 28, pour 60 attributs + la force de morsure. Les données sont organisées dans deux fichiers csv différents, l'un contenant les attributs utilisés pour la prédiction, et l'autre contenant une unique colonne de force de morsure.\n",
    "\n",
    "L'enjeu est de réussir à faire de la sélection de variables et à travailler sur ce jeu de données avec un nombre d'exemples aussi faible. \n",
    "\n",
    "## Démarrage\n",
    "\n",
    "Importons les bibliothèques qui nous serons utiles dans la suite, et chargeons les données avec un premier affichage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee9651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Chargement des données\n",
    "X_lz = pd.read_csv('donnees_entrainement.csv')\n",
    "y_lz = pd.read_csv('donnees_resultat.csv')\n",
    "\n",
    "#Aperçu des données\n",
    "apercu_attributs = X_lz.head()\n",
    "info_attributs = X_lz.info()\n",
    "apercu_cible = y_lz.head()\n",
    "info_cible = y_lz.info()\n",
    "\n",
    "print(apercu_attributs, info_attributs, apercu_cible, info_cible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c7995",
   "metadata": {},
   "source": [
    "Effectuons un one-hot-encoding sur l'attribut de sexe, de sorte à pourvoir l'intégrer plus facilement aux analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c67ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding sur 'Sex'\n",
    "X_lz = pd.get_dummies(X_lz, columns=['Sex'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f242987",
   "metadata": {},
   "source": [
    "La colonne 'Sex' est remplacée par une colonne 'Sex_male' de valeur 0 ou 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8bdc2",
   "metadata": {},
   "source": [
    "## Nettoyage des valeurs\n",
    "\n",
    "Procédons à présent au nettoyage des données, et particulièrement à la gestion des valeurs manquantes. Cette étape est essentielle pour mener toute analyse.\n",
    "\n",
    "Affichons les valeurs manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage du nombre de valeurs manquantes par colonne\n",
    "missing_values = X_lz.isnull().sum()\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6d9327",
   "metadata": {},
   "source": [
    "En comparaison du nombre d'attributs, <span style=\"color: #159b36\">il y a très peu de colonnes affectées par des valeurs manquantes </span>.\n",
    "\n",
    "Au vu du faible nombre d'exemples, au-delà d'un quart de données manquantes, considérons que l'on n'utilisons pas la colonne ; en dessous, on va faire une imputation, d'autant plus pertinent que le seul cas restant une fois les colonnes lacunaires éliminées est une unique valeur manquante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63077aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil=0.25*len(X_lz)\n",
    "\n",
    "#Suppression des colonnes avec plus de 25% de valeurs manquantes\n",
    "colonnes_a_supprimer = X_lz.columns[X_lz.isnull().sum() > seuil]\n",
    "X_lz = X_lz.drop(columns=colonnes_a_supprimer)\n",
    "\n",
    "print(\"Colonnes supprimées :\", colonnes_a_supprimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9270ecb",
   "metadata": {},
   "source": [
    "Les colonnes trop vides ont été éliminées ; place à la gestion des valeurs manquantes restantes. Nous allons les remplaces par la moyenne des valeurs présentes sur la colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc566f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Imputation des valeurs manquantes des colonnes avec problèmes restantes\n",
    "colonnes_a_imputer = X_lz.columns[X_lz.isnull().sum()>0]\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')    #on utilise la moyenne\n",
    "\n",
    "if len(colonnes_a_imputer)>0:\n",
    "    for colonne in colonnes_a_imputer:\n",
    "        X_imput=imputer.fit_transform(X_lz[[colonne]])\n",
    "        X_lz[[colonne]] = pd.DataFrame(X_imput, columns=[colonne], index=X_lz.index)\n",
    "\n",
    "\n",
    "#Vérifions qu'il n'y a plus de valeurs manquantes\n",
    "print(X_lz.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004277c7",
   "metadata": {},
   "source": [
    "Il n'y a à présent <span style=\"color: #159b36\">plus aucune valeur manquante, nous pouvons passer à l'analyse des données</span>. Il est à noter qu'au vu de la taille du jeu de données, tout ce nettoyage aurait pu facilement être réalisé à la main. Nous avons cependant ici un bout de script qui pourra être réutilisé dans d'autres contextes plus complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825a25c",
   "metadata": {},
   "source": [
    "## Recherche de corrélations\n",
    "\n",
    "Une première étape pour la sélection de variables est la recherche de corrélations entre les attributs et la force de morsure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549ba07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = np.abs(X_lz.select_dtypes(include=[np.float64]).T@y_lz)\n",
    "noms=list(X_lz.columns)\n",
    "noms.pop(0)     #on retire la colonne de noms d'espèces\n",
    "noms.pop(-1)    #on retire la colonne du sexe\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.bar(noms, corr['bite force_w'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f22b57",
   "metadata": {},
   "source": [
    "Conclusions :\n",
    "\n",
    "- <span style=\"color: #159b36\">assez logiquement, les données de dissections et les données de terrain donnent la même forme ; on retirera les données de terrain</span>\n",
    "\n",
    "- <span style=\"color: #159b36\"> quelques variables semblent se dégager, mais probablement plus à cause de leur valeur absolue par rapport aux autres</span>\n",
    "\n",
    "Retirons donc les données de terrain, ainsi que le nom des espèces qui joue plus un rôle d'identifiant dans ce contexte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f880baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lz=X_lz.drop(columns= ['SVL_w', 'headl_w', 'headW_w', 'headh_w', 'lower jawl_w', 'tip-quadr_w', 'tip-coron_w', 'opening_w', 'closing_w'])\n",
    "X_lz=X_lz.drop(columns= ['Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc94dd",
   "metadata": {},
   "source": [
    "Maintenant que les colonnes superflues ont été retirées, observons à nouveau les corrélations avec une matrice de corrélation, plus lisible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c26965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data=X_lz.copy()    #dopy très important pour ne pas modifier X_lz !\n",
    "data['bite_force_w'] = y_lz['bite force_w']\n",
    "\n",
    "corr_2=data.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_2, cmap='coolwarm', linewidths=0.5)   #pour une matrice plus agréable à lire\n",
    "plt.title(\"Corrélation des caractéristiques\", fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b141e6",
   "metadata": {},
   "source": [
    "<span style=\"color: #159b36\">De nouvelles variables se dégagent, et notamment celles relative à la masse des muscles ainsi que leur section. Ces observations sont en accord avec les conclusions de l'article dont sont issues les données.</span>\n",
    "\n",
    "## Sélection de variables avec le SequentialFeatureSelector\n",
    "\n",
    "Regardons si le SFS peut extraire un certain nombre de variables. L'objectif est d'en avoir 7 au final, et d'ajouter dedans le sexe ; nous en cherchons donc 6. Cela permet d'avoir un nombre de variables plus faible que le nombre d'exemple, 4 fois plus faible précisément.\n",
    "\n",
    "Après avoir réalisé beaucoup d'essais en changeant de modèles, de plis pour la validation croisée et de direction, choisissons d'utiliser un <span style=\"color: #159b36\">Random Forest avec 5 plis en direction \"forward\"</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "estimator = RandomForestRegressor()\n",
    "selector = SequentialFeatureSelector(estimator, n_features_to_select=6, cv=5)\n",
    "selector = selector.fit(X_lz, y_lz)\n",
    "selected_features = X_lz.columns[selector.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580d644",
   "metadata": {},
   "source": [
    "<span style=\"color: #159b36\">À chaque essai, les features sélectionnées changent, il n'y a aucune stabilité dans la sortie. Aussi, pour la sélection finale et faciliter la reproduction des résultats, fixons les variables ayant données les meilleurs résultats en apprentissage, qui sont celles se dégageant le plus dans la matrice de corrélation.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e205cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features=['headh', 'DM_muscle_mass', 'AMESP_muscle_mass', 'PSTP_muscle_mass', 'PSTP_physiological_cross_sectional_area', 'AMP_physiological_cross_sectional_area']     #choix basé sur ce qui revenait régulièrement lors de mes essais + matrice de corrélation\n",
    "\n",
    "Xf=[]\n",
    "X_final=pd.DataFrame(Xf)\n",
    "for attribut in selected_features:\n",
    "    X_final[attribut]=X_lz[attribut]\n",
    "X_final['Sex_male']=X_lz['Sex_male'] #choix d'ajouter sexe car j'ai constaté que c'est important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc010a3e",
   "metadata": {},
   "source": [
    "## Début de l'apprentissage\n",
    "\n",
    "Recherchons le modèle donnant les meilleurs résultats bruts parmis un ensemble de modèles possibles. Les modèles testés sont la régression linéaire, ridge, lasso, ElasticNet, les k plus proches voisins, SVR, random forest et XGBoost. On effectue un leave-one-out au vu du très faible nombre d'exemples à notre disposition. La métrique d'évaluation est l'erreur quadratique moyenne (en anglais Mean Squared Error, MSE), soit la moyenne des carrés des erreurs entre les prédictions et les valeurs réelles. L'implémentation du MSE dans sckiit-learn est telle qu'elle est donnée négativement, il faut bien prendre cela en compte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e729e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_moyens=[]   #stockons les résultats\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens.append('LR')\n",
    "scores_moyens.append(mean_score)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_model = Ridge()\n",
    "scores = cross_val_score(ridge_model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens.append('Ridge')\n",
    "scores_moyens.append(mean_score)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_model = Lasso()\n",
    "scores = cross_val_score(lasso_model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens.append('Lasso')\n",
    "scores_moyens.append(mean_score)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_model = ElasticNet()\n",
    "scores = cross_val_score(elastic_model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens.append('ElasticNet')\n",
    "scores_moyens.append(mean_score)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_model = KNeighborsRegressor()\n",
    "scores = cross_val_score(knn_model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens.append('KNN')\n",
    "scores_moyens.append(mean_score)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svr_model = SVR(kernel='linear') #arbitrairement, linéaire\n",
    "scores = cross_val_score(svr_model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens.append('SVR')\n",
    "scores_moyens.append(mean_score)\n",
    "\n",
    "rfr_model = RandomForestRegressor()\n",
    "scores = cross_val_score(rfr_model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens.append('RFR')\n",
    "scores_moyens.append(mean_score)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "xgb_model = XGBRegressor()\n",
    "scores = cross_val_score(xgb_model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens.append('XGB')\n",
    "scores_moyens.append(mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a497596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_moyens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290ba65b",
   "metadata": {},
   "source": [
    "Nous constatons que <span style=\"color: #159b36\">le SVR est, et de loin, le meilleur modèle. Ce modèle est optimisable ; cherchons donc à l'améliorer à l'aide d'optuna, et optimisons également les trois modèles suivant en performance pour voir si l'un deux prendra le dessus une fois optimisé</span>.\n",
    "## Optimisation de modèles\n",
    "\n",
    "\n",
    "Nous allons chercher à optimiser chaque paramètre du SVR, ridge, ElasticNet et lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83213004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "#Optimisation SVR\n",
    "def objective_svr(trial):\n",
    "# Hyperparamètres à optimiser\n",
    "    params = {\n",
    "        'C': trial.suggest_loguniform('C', 1e-3, 1e3),\n",
    "        'epsilon': trial.suggest_loguniform('epsilon', 1e-4, 1e1),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    }\n",
    "\n",
    "#Paramètres supplémentaires pour les kernels 'poly' et 'rbf'\n",
    "    if params['kernel'] == 'poly':\n",
    "        params['degree'] = trial.suggest_int('degree', 2, 5)\n",
    "        params['coef0'] = trial.suggest_uniform('coef0', 0.0, 10.0)\n",
    "    if params['kernel'] in ['poly', 'rbf', 'sigmoid']:\n",
    "        params['gamma'] = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
    "\n",
    "#Création et entraînement du modèle\n",
    "    model = SVR(**params)\n",
    "    scores = cross_val_score(model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Retourner la moyenne de l'erreur quadratique moyenne négative\n",
    "    return np.mean(scores)\n",
    "\n",
    "study_svr = optuna.create_study(direction='maximize')   #maximisation de la métrique d'évaluation car elle est donnée négative\n",
    "study_svr.optimize(objective_svr, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimisation ridge\n",
    "def objective_ridge(trial):\n",
    "# Hyperparamètre à optimiser\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-4, 1e3)\n",
    "\n",
    "#Création et entraînement du modèle\n",
    "    model = Ridge(alpha=alpha)\n",
    "    scores = cross_val_score(model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Retourner la moyenne de l'erreur quadratique moyenne négative\n",
    "    return np.mean(scores)\n",
    "\n",
    "study_ridge = optuna.create_study(direction='maximize')   #maximisation de la métrique d'évaluation car elle est donnée négative\n",
    "study_ridge.optimize(objective_ridge, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed145dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_elasticnet(trial):\n",
    "# Hyperparamètres à optimiser\n",
    "    params = {\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
    "        'l1_ratio': trial.suggest_uniform('l1_ratio', 0.0, 1.0)\n",
    "    }\n",
    "\n",
    "#Création et entraînement du modèle\n",
    "    model = ElasticNet(**params, max_iter=10000)\n",
    "    scores = cross_val_score(model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Retourner la moyenne de l'erreur quadratique moyenne négative\n",
    "    return np.mean(scores)\n",
    "\n",
    "study_elasticnet = optuna.create_study(direction='maximize')   #maximisation de la métrique d'évaluation car elle est donnée négative\n",
    "study_elasticnet.optimize(objective_elasticnet, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lasso(trial):\n",
    "# Hyperparamètre à optimiser\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-4, 1e2)\n",
    "\n",
    "#Création et entraînement du modèle Lasso\n",
    "    model = Lasso(alpha=alpha, max_iter=10000)\n",
    "    scores = cross_val_score(model, X_final, y_lz, cv=loo, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Retourner la moyenne de l'erreur quadratique moyenne négative\n",
    "    return np.mean(scores)\n",
    "\n",
    "study_lasso = optuna.create_study(direction='maximize')   #maximisation de la métrique d'évaluation car elle est donnée négative\n",
    "study_lasso.optimize(objective_lasso, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleurs hyperparamètres pour SVR :\", study_svr.best_params)\n",
    "print(\"Meilleure valeur de MSE pour SVR :\", study_svr.best_value)\n",
    "print(\"Meilleurs hyperparamètres pour ridge :\", study_ridge.best_params)\n",
    "print(\"Meilleure valeur de MSE pour ridge :\", study_ridge.best_value)\n",
    "print(\"Meilleurs hyperparamètres pour elasticnet :\", study_elasticnet.best_params)\n",
    "print(\"Meilleure valeur de MSE pour elasticnet :\", study_elasticnet.best_value)\n",
    "print(\"Meilleurs hyperparamètres pour lasso :\", study_lasso.best_params)\n",
    "print(\"Meilleure valeur de MSE pour lasso :\", study_lasso.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f03c68",
   "metadata": {},
   "source": [
    "Après optimisation, <span style=\"color: #159b36\">le SVR reste le meilleur des modèles. Nous sommes en mesure de faire passer le MSE de environ 17 à environ 12,5 avec les paramètres suivants : un noyau poly, C = 1.216712493672062, epsilon = 0.5854463926783681, degree = 2, coef0 = 8.613116087425539 et gamma = 0.017014770725644102. Cela donne un écart moyen entre la valeur réelle et la valeur prédite d'environ 3,5 newtons. Une grande partie des valeurs de force de morsure se situe en-dessous de cette erreur, et une autre grande partie est proportionnellement petite par rapport à l'erreur. La prédiction est donc peu fiable dans la plupart des cas. Cela peut s'expliquer par la présence de quelques exemples avec une force remarquablement plus importante que les autres ; leur écart doit fausser l'apprentissage. Notre modèle gagnerait probablement à être entraîné sur des jeux de données de lézards forts et faibles, et serait probablement très bon dans ce contexte. Dans le cadre d'un jeu de données avec de grands écarts, les performances sont donc globalement très correctes. </span>\n",
    "## Subdivision du jeu de données\n",
    "\n",
    "Retirons les colonnes avec la plus grande valeur de force pour voir si retirer les outliers rends la prédiction meilleure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "valeurs_morsures_triees = y_lz['bite force_w'].sort_values(ascending=False)  # Convertir en liste si besoin\n",
    "print(valeurs_morsures_triees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5919a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = y_lz.index\n",
    "valeurs = y_lz['bite force_w']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(index, valeurs, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Valeur de force de morsure\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06203a3e",
   "metadata": {},
   "source": [
    "Une valeurs se dégage particulièrement, à laquelle on peut en ajouter cinq autres au-dessus de la masse ; retirons-les. Au vu de leur faible nombre, il ne serait pas pertinent de les mettre dans un nouveau jeu de données à explorer séparément."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b1dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_a_supprimer = y_lz['bite force_w'].nlargest(6).index\n",
    "print(index_a_supprimer)\n",
    "X_faibles=X_final.copy()\n",
    "y_faibles=y_lz.copy()\n",
    "X_faibles=X_faibles.drop(index=index_a_supprimer)\n",
    "y_faibles=y_faibles.drop(index=index_a_supprimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcff5e6",
   "metadata": {},
   "source": [
    "Nous avons nos nouvelles données avec les outliers retirés. Les conclusions précédentes sur le SVR et les optimisations ayant été obtenues à partir des données intégrales, recommençons le processus précédent de sélection de modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcce4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_moyens_2=[]   #stockons les résultats\n",
    "\n",
    "#LR\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens_2.append('LR')\n",
    "scores_moyens_2.append(mean_score)\n",
    "\n",
    "#Ridge\n",
    "ridge_model = Ridge()\n",
    "scores = cross_val_score(ridge_model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens_2.append('Ridge')\n",
    "scores_moyens_2.append(mean_score)\n",
    "\n",
    "#Lasso\n",
    "lasso_model = Lasso()\n",
    "scores = cross_val_score(lasso_model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens_2.append('Lasso')\n",
    "scores_moyens_2.append(mean_score)\n",
    "\n",
    "#ElasticNet\n",
    "elastic_model = ElasticNet()\n",
    "scores = cross_val_score(elastic_model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens_2.append('ElasticNet')\n",
    "scores_moyens_2.append(mean_score)\n",
    "\n",
    "#KNN\n",
    "knn_model = KNeighborsRegressor()\n",
    "scores = cross_val_score(knn_model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens_2.append('KNN')\n",
    "scores_moyens_2.append(mean_score)\n",
    "\n",
    "#SVR\n",
    "svr_model = SVR(kernel='linear') #arbitrairement, linéaire\n",
    "scores = cross_val_score(svr_model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens_2.append('SVR')\n",
    "scores_moyens_2.append(mean_score)\n",
    "\n",
    "#RFR\n",
    "rfr_model = RandomForestRegressor()\n",
    "scores = cross_val_score(rfr_model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens_2.append('RFR')\n",
    "scores_moyens_2.append(mean_score)\n",
    "\n",
    "#XGB\n",
    "xgb_model = XGBRegressor()\n",
    "scores = cross_val_score(xgb_model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "mean_score = np.mean(scores)\n",
    "scores_moyens_2.append('XGB')\n",
    "scores_moyens_2.append(mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b948ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_moyens_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd6de5",
   "metadata": {},
   "source": [
    "<span style=\"color: #159b36\">Les performances sont d'entrée de jeu bien meilleures et bien plus serrées, avec cette fois-ci ElasticNet qui se dégage, suivi de près par lasso et d'un peu plus loin par random forest. </span> Essayons d'optimiser ces trois modèles avec optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_elasticnet_2(trial):\n",
    "# Hyperparamètres à optimiser\n",
    "    params = {\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
    "        'l1_ratio': trial.suggest_uniform('l1_ratio', 0.0, 1.0)\n",
    "    }\n",
    "\n",
    "#Création et entraînement du modèle\n",
    "    model = ElasticNet(**params, max_iter=10000)\n",
    "    scores = cross_val_score(model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Retourner la moyenne de l'erreur quadratique moyenne négative\n",
    "    return np.mean(scores)\n",
    "\n",
    "study_elasticnet_2 = optuna.create_study(direction='maximize')   #maximisation de la métrique d'évaluation car elle est donnée négative\n",
    "study_elasticnet_2.optimize(objective_elasticnet_2, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lasso_2(trial):\n",
    "# Hyperparamètre à optimiser\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-4, 1e2)\n",
    "\n",
    "#Création et entraînement du modèle Lasso\n",
    "    model = Lasso(alpha=alpha, max_iter=10000)\n",
    "    scores = cross_val_score(model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Retourner la moyenne de l'erreur quadratique moyenne négative\n",
    "    return np.mean(scores)\n",
    "\n",
    "study_lasso_2 = optuna.create_study(direction='maximize')   #maximisation de la métrique d'évaluation car elle est donnée négative\n",
    "study_lasso_2.optimize(objective_lasso_2, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rfr(trial):\n",
    "# Hyperparamètres à optimiser\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "\n",
    "#Création et entraînement du modèle\n",
    "    model = RandomForestRegressor(**params, random_state=42)\n",
    "    scores = cross_val_score(model, X_faibles, y_faibles, cv=loo, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Retourner la moyenne de l'erreur quadratique moyenne\n",
    "    return np.mean(scores)\n",
    "\n",
    "study_rfr = optuna.create_study(direction='maximize')   #maximisation de la métrique d'évaluation car elle est donnée négative\n",
    "study_rfr.optimize(objective_rfr, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f405195",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleurs hyperparamètres pour ElasticNet :\", study_elasticnet_2.best_params)\n",
    "print(\"Meilleure valeur de MSE pour ElasticNet :\", study_elasticnet_2.best_value)\n",
    "print(\"Meilleurs hyperparamètres pour lasso :\", study_lasso_2.best_params)\n",
    "print(\"Meilleure valeur de MSE pour lasso :\", study_lasso_2.best_value)\n",
    "print(\"Meilleurs hyperparamètres pour random forest :\", study_rfr.best_params)\n",
    "print(\"Meilleure valeur de MSE pour random forest :\", study_rfr.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235722e8",
   "metadata": {},
   "source": [
    "<span style=\"color: #159b36\">ElasticNet reste le meilleur modèle après optimisation ; nous sommes en mesure de lui faire gagner environ 0,2 points avec les paramètres suivants : alpha = 1.913255964637761 et l1_ratio = 2.7280103109729708e-05. Cette amélioration est satisfaisante au vue de la faible valeur initiale de MSE. Notre modèle final devient donc bien meilleur une fois les données séparées des outliers. Considérant que l'erreur est la moyenne des écarts au carré, les performances sont finalement très bonnes. </span>\n",
    "## Conclusion\n",
    "\n",
    "<span style=\"color: #159b36\">Considérant la taille très réduite du jeu de données et le nombre d'attribut, le modèle final parvient à estimer la force de morsure de lézards de manière assez satisfaisante. Nous avons vu l'importance de l'homogénéité des données dans ce contexte, au point de changer de modèle de prédilection une fois celles-ci séparées des outliers.</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
